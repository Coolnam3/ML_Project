{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PRJ-002: Diabetes 130-US Hospitals for Years 1999-2008 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "admission_type_id={1:\"Emergency\", 2:\"Urgent\", 3:\"Elective\",4:\"Newborn\",5:\"Not Available\",6:\"NULL\",7:\"Not Mapped\"}\n",
    "\n",
    "discharge_disposition_id = {\n",
    "    1: \"Discharged to home\",\n",
    "    2: \"Discharged/transferred to another short term hospital\",\n",
    "    3: \"Discharged/transferred to SNF\",\n",
    "    4: \"Discharged/transferred to ICF\",\n",
    "    5: \"Discharged/transferred to another type of inpatient care institution\",\n",
    "    6: \"Discharged/transferred to home with home health service\",\n",
    "    7: \"Left AMA\",\n",
    "    8: \"Discharged/transferred to home under care of Home IV provider\",\n",
    "    9: \"Admitted as an inpatient to this hospital\",\n",
    "    10: \"Neonate discharged to another hospital for neonatal aftercare\",\n",
    "    11: \"Expired\",\n",
    "    12: \"Still patient or expected to return for outpatient services\",\n",
    "    13: \"Hospice / home\",\n",
    "    14: \"Hospice / medical facility\",\n",
    "    15: \"Discharged/transferred within this institution to Medicare approved swing bed\",\n",
    "    16: \"Discharged/transferred/referred another institution for outpatient services\",\n",
    "    17: \"Discharged/transferred/referred to this institution for outpatient services\",\n",
    "    18: \"NULL\",\n",
    "    19: \"Expired at home. Medicaid only, hospice.\",\n",
    "    20: \"Expired in a medical facility. Medicaid only, hospice.\",\n",
    "    21: \"Expired, place unknown. Medicaid only, hospice.\",\n",
    "    22: \"Discharged/transferred to another rehab fac including rehab units of a hospital\",\n",
    "    23: \"Discharged/transferred to a long term care hospital\",\n",
    "    24: \"Discharged/transferred to a nursing facility certified under Medicaid but not certified under Medicare.\",\n",
    "    25: \"Not Mapped\",\n",
    "    26: \"Unknown/Invalid\",\n",
    "    30: \"Discharged/transferred to another Type of Health Care Institution not Defined Elsewhere\",\n",
    "    27: \"Discharged/transferred to a federal health care facility.\",\n",
    "    28: \"Discharged/transferred/referred to a psychiatric hospital or psychiatric distinct part unit of a hospital\",\n",
    "    29: \"Discharged/transferred to a Critical Access Hospital (CAH).\"\n",
    "}\n",
    "\n",
    "admission_source_id = {\n",
    "    1: \"Physician Referral\",\n",
    "    2: \"Clinic Referral\",\n",
    "    3: \"HMO Referral\",\n",
    "    4: \"Transfer from a hospital\",\n",
    "    5: \"Transfer from a Skilled Nursing Facility (SNF)\",\n",
    "    6: \"Transfer from another health care facility\",\n",
    "    7: \"Emergency Room\",\n",
    "    8: \"Court/Law Enforcement\",\n",
    "    9: \"Not Available\",\n",
    "    10: \"Transfer from critical access hospital\",\n",
    "    11: \"Normal Delivery\",\n",
    "    12: \"Premature Delivery\",\n",
    "    13: \"Sick Baby\",\n",
    "    14: \"Extramural Birth\",\n",
    "    15: \"Not Available\",\n",
    "    17: \"NULL\",\n",
    "    18: \"Transfer From Another Home Health Agency\",\n",
    "    19: \"Readmission to Same Home Health Agency\",\n",
    "    20: \"Not Mapped\",\n",
    "    21: \"Unknown/Invalid\",\n",
    "    22: \"Transfer from hospital inpt/same fac reslt in a sep claim\",\n",
    "    23: \"Born inside this hospital\",\n",
    "    24: \"Born outside this hospital\",\n",
    "    25: \"Transfer from Ambulatory Surgery Center\",\n",
    "    26: \"Transfer from Hospice\"\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports\n",
    "Copied from previous project to have a foundation. We can delete unused ones later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from scipy.stats import gaussian_kde\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import StandardScaler, OrdinalEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.cluster import MiniBatchKMeans\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import dataset and print basic info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"diabetic_data.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All rows seem to have no null values but it is incorrect. The null values are defined with a question mark. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Handle missing values\n",
    "Some of the features are missing many values to make a significant difference and some are not useful e.g. 'patient_nbr'\n",
    "\n",
    "Below are plots showing how many percent of the features are NaN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_counts = data.shape[0]\n",
    "\n",
    "# Calculate the number of ? values in each column\n",
    "question_mark_counts = data.apply(lambda col: col.astype(str).str.count(r'\\?').sum())\n",
    "\n",
    "question_mark_percentage = (question_mark_counts / total_counts) * 100\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "question_mark_percentage.plot(kind='bar', color='skyblue')\n",
    "plt.title(\"Percentage of '?' in Each Column\")\n",
    "plt.xlabel(\"Columns\")\n",
    "plt.ylabel(\"Percentage of '?' (%)\")\n",
    "plt.ylim(0, 100)  # Set y-axis from 0 to 100% for clarity\n",
    "plt.xticks(rotation=90)\n",
    "\n",
    "# Add percentage labels on top of each bar\n",
    "for idx, value in enumerate(question_mark_percentage):\n",
    "    if(value>0):\n",
    "        plt.text(idx, value + 1, f'{value:.2f}%', ha='center', va=('top' if value>10 else 'bottom'), fontsize=10, rotation=90)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some of features contain many values that are the same e.g. most of the drug features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the number of NaN values in each column\n",
    "no_counts = data.apply(lambda col: col.astype(str).str.count('No').sum())\n",
    "\n",
    "no_percentage = (no_counts / total_counts) * 100\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "no_percentage.plot(kind='bar', color='skyblue')\n",
    "plt.title(\"Percentage of 'No' in Each Column\")\n",
    "plt.xlabel(\"Columns\")\n",
    "plt.ylabel(\"Percentage of 'No' (%)\")\n",
    "plt.ylim(0, 100)  # Set y-axis from 0 to 100% for clarity\n",
    "plt.xticks(rotation=90)\n",
    "\n",
    "# Add percentage labels on top of each bar\n",
    "for idx, value in enumerate(no_percentage):\n",
    "    if(value>1):\n",
    "        plt.text(idx, value + 1, f'{value:.2f}%', ha='center', va=('top' if value>10 else 'bottom'), fontsize=10, rotation=90)\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feature that are not useful:\n",
    "\n",
    "|Feature|Explanation|\n",
    "|---|---|\n",
    "|encounter_id| Is unique|\n",
    "|patient_nbr|Is unique|\n",
    "|weight|Over 95 % missing values|\n",
    "|max_glu_serum|Over 95 % does not take this drug|\n",
    "|repaglinide|Over 95 % does not take this drug|\n",
    "|nateglinide|Over 95 % does not take this drug|\n",
    "|chlorpropamide|Over 95 % does not take this drug|\n",
    "|acetohexamide|Same values for all rows|\n",
    "|tolbutamide|Over 95 % does not take this drug|\n",
    "|acarbose|Over 95 % does not take this drug|\n",
    "|miglitol|Over 95 % does not take this drug|\n",
    "|troglitazone|Same values for all rows|\n",
    "|tolazamide|Over 95 % does not take this drug|\n",
    "|examide|Same values for all rows|\n",
    "|citoglipton|Same values for all rows|\n",
    "|glyburide-metformin|Over 95 % does not take this drug|\n",
    "|glipizide-metformin|Over 95 % does not take this drug|\n",
    "|glimepiride-pioglitazone|Same values for all rows|\n",
    "|metformin-rosiglitazone|Same values for all rows|\n",
    "|metformin-pioglitazone|Same values for all rows|\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_drop=['weight','patient_nbr','encounter_id',\n",
    "                 'repaglinide','nateglinide','chlorpropamide',\n",
    "                 'acetohexamide','tolbutamide','acarbose','miglitol',\n",
    "                 'troglitazone','tolazamide','examide', 'citoglipton',\n",
    "                 'glyburide-metformin','glipizide-metformin',\n",
    "                 'glimepiride-pioglitazone','metformin-rosiglitazone',\n",
    "                 'metformin-pioglitazone','max_glu_serum']\n",
    "\n",
    "data.drop(columns=columns_to_drop,  inplace=True)\n",
    "\n",
    "# Many missing values, but potentially high relevance\n",
    "data['medical_specialty'].fillna('Unknown', inplace=True)\n",
    "\n",
    "# Few missing values\n",
    "data['race'].fillna('Unknown', inplace=True)\n",
    "data['diag_1'].fillna('Unknown', inplace=True)\n",
    "data['diag_2'].fillna('Unknown', inplace=True)\n",
    "data['diag_3'].fillna('Unknown', inplace=True)\n",
    "\n",
    "# Remove 3 rows where gender is \"Unknown/Invalid\"\n",
    "data = data[data['gender'] != 'Unknown/Invalid']\n",
    "\n",
    "#Replace '?' with other\n",
    "data.replace('?', 'Other', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Encode Binary columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['gender'] = data['gender'].map({'Male': 1, 'Female': 0}).astype('int64')\n",
    "data['change'] = data['change'].map({'Ch': 1, 'No': 0}).astype('int64')\n",
    "data['diabetesMed'] = data['diabetesMed'].map({'Yes': 1, 'No': 0}).astype('int64')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Encode all medicine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Numeric mapping for medication columns\n",
    "medication_columns = ['metformin','glimepiride','glipizide', 'glyburide','pioglitazone','rosiglitazone', 'insulin']\n",
    "\n",
    "data[medication_columns] = data[medication_columns].replace({'Steady': 1, 'No': 0, 'Down': -1, 'Up': 2})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Encode the categorical columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_colums=['race','payer_code','medical_specialty',]\n",
    "\n",
    "# One-Hot Encoding for categorical columns\n",
    "data = pd.get_dummies(data, columns=categorical_colums, drop_first=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Encode Ordinal columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "data['age'] = data['age'].map({'[0-10)':0, '[10-20)':1, '[20-30)':2, '[30-40)':3, '[40-50)':4, '[50-60)':5, '[60-70)':6, '[70-80)':7, '[80-90)':8, '[90-100)':9}).astype('int64')\n",
    "\n",
    "data['readmitted'] = data['readmitted'].map({'NO': 0, '<30': 1,'>30':2}).astype('int64')\n",
    "\n",
    "data['A1Cresult'] = data['A1Cresult'].map({'None': 0, 'Norm': 1,'>7':2,'>8':3}).astype('int64')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Encode the diagnoses\n",
    "\n",
    "The diagnoses are encoded with ICD-9. https://en.wikipedia.org/wiki/List_of_ICD-9_codes\n",
    "This means we can categorize them into 19 categories to simplify the data. E and V being divided into 2 categories instead of one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_diag(value):\n",
    "    if isinstance(value,str) and (value.startswith('E') or value.startswith('V') or value.startswith('O')):\n",
    "        if value.startswith('E'):\n",
    "            return 17\n",
    "        elif value.startswith('V'):\n",
    "            return 18\n",
    "        elif value.startswith('O'): #When its other\n",
    "            return -1\n",
    "    else:\n",
    "        value=float(value)\n",
    "        if value <= 139:\n",
    "            return 0\n",
    "        elif 140 <= value <= 239:\n",
    "            return 1\n",
    "        elif 240 <= value <= 279:\n",
    "            return 2\n",
    "        elif 280 <= value <= 289:\n",
    "            return 3\n",
    "        elif 290 <= value <= 319:\n",
    "            return 4\n",
    "        elif 320 <= value <= 389:\n",
    "            return 5\n",
    "        elif 390 <= value <= 459:\n",
    "            return 6\n",
    "        elif 460 <= value <= 519:\n",
    "            return 7\n",
    "        elif 520 <= value <= 579:\n",
    "            return 8\n",
    "        elif 580 <= value <= 629:\n",
    "            return 9\n",
    "        elif 630 <= value <= 679:\n",
    "            return 10\n",
    "        elif 680 <= value <= 709:\n",
    "            return 11\n",
    "        elif 710 <= value <= 739:\n",
    "            return 12\n",
    "        elif 740 <= value <= 759:\n",
    "            return 13\n",
    "        elif 760 <= value <= 779:\n",
    "            return 14\n",
    "        elif 780 <= value <= 799:\n",
    "            return 15\n",
    "        elif 800 <= value <= 999:\n",
    "            return 16\n",
    "\n",
    "data['diag_1']= data['diag_1'].apply(map_diag) \n",
    "data['diag_2']= data['diag_2'].apply(map_diag) \n",
    "data['diag_3']= data['diag_3'].apply(map_diag) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check if it worked\n",
    "data['diag_1'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split into features and target\n",
    "X = data.drop('readmitted', axis=1)\n",
    "y = data['readmitted']\n",
    "\n",
    "# Split into training and testing\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "numerical_features = ['time_in_hospital', 'num_lab_procedures', 'num_procedures', 'num_medications', 'number_outpatient', 'number_emergency', 'number_inpatient']\n",
    "X_train[numerical_features] = scaler.fit_transform(X_train[numerical_features])\n",
    "X_test[numerical_features] = scaler.transform(X_test[numerical_features])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing for missing values, troubleshooting\n",
    "print(\"Missing values in X_train:\", X_train.isnull().sum().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model choice\n",
    "We decided to start with two classification and one clustering algorithm.\n",
    "### Logistic Regression\n",
    "- Effective for rougly linear relationships\n",
    "- Interpretable (giving us an idea of the meaning of each feature)\n",
    "- Efficient for large datasets\n",
    "### Random Forest\n",
    "- Captures complex, non-linear relationships (good counterpart to Logisitc Regression)\n",
    "- Allows determining feature importance\n",
    "- Usually performs well without hypertuning\n",
    "### K-Means Clustering\n",
    "- Easy to interpret\n",
    "- Effective for grouping patients with similar characteristics\n",
    "- Might still be fast enough for a dataset of our size\n",
    "- There are different ways to make K-Means faster, if needed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def plot_feature_importances(model, top_n=None):\n",
    "    \"\"\"\n",
    "    Plots the feature importances of a model.\n",
    "\n",
    "    Parameters:\n",
    "    - model: A trained model with a `feature_importances_` attribute (e.g., tree-based models).\n",
    "    - X_train: Training data as a DataFrame (to automatically retrieve feature names).\n",
    "    - top_n: Integer specifying the number of top features to plot. If None, all features are plotted.\n",
    "\n",
    "    \"\"\"\n",
    "    # Retrieve feature importances from the model\n",
    "    importances = model.feature_importances_\n",
    "    \n",
    "    # Determine feature names from X_train if provided, otherwise use generic names\n",
    "    \n",
    "    feature_names = X_train.columns\n",
    "    \n",
    "    \n",
    "    # Combine feature names and their importance scores\n",
    "    feature_importance_pairs = list(zip(feature_names, importances))\n",
    "    \n",
    "    # Sort features by importance\n",
    "    feature_importance_pairs = sorted(feature_importance_pairs, key=lambda x: x[1], reverse=True)\n",
    "    \n",
    "    # If specified, select only the top_n features\n",
    "    if top_n is not None:\n",
    "        feature_importance_pairs = feature_importance_pairs[:top_n]\n",
    "    \n",
    "    # Separate the feature names and their scores after sorting\n",
    "    features, importance_scores = zip(*feature_importance_pairs)\n",
    "    \n",
    "    # Plotting\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.barh(features, importance_scores, color=\"skyblue\")\n",
    "    plt.xlabel(\"Feature Importance\")\n",
    "    plt.ylabel(\"Features\")\n",
    "    plt.title(\"Feature Importances\")\n",
    "    plt.gca().invert_yaxis()  # Invert y-axis to have the highest importance at the top\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize\n",
    "log_reg = LogisticRegression(max_iter=1000, random_state=42)\n",
    "\n",
    "# train\n",
    "log_reg.fit(X_train, y_train)\n",
    "\n",
    "# Predict\n",
    "y_pred_log_reg = log_reg.predict(X_test)\n",
    "\n",
    "# Evaluate\n",
    "print(\"Logistic Regression Accuracy:\", accuracy_score(y_test, y_pred_log_reg))\n",
    "print(classification_report(y_test, y_pred_log_reg))\n",
    "print(confusion_matrix(y_test, y_pred_log_reg))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming you have a DataFrame X for features and y for labels\n",
    "rfc = RandomForestClassifier()\n",
    "rfc.fit(X_train, y_train)\n",
    "\n",
    "rfc_y_pred = rfc.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_feature_importances(rfc,25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Evaluate\n",
    "\n",
    "print(\"Logistic Regression Accuracy:\", accuracy_score(y_test,rfc_y_pred))\n",
    "print(classification_report(y_test, rfc_y_pred))\n",
    "print(confusion_matrix(y_test, rfc_y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Seminar2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
