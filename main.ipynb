{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PRJ-002: Diabetes 130-US Hospitals for Years 1999-2008 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "admission_type_id={1:\"Emergency\", 2:\"Urgent\", 3:\"Elective\",4:\"Newborn\",5:\"Not Available\",6:\"NULL\",7:\"Not Mapped\"}\n",
    "\n",
    "discharge_disposition_id = {\n",
    "    1: \"Discharged to home\",\n",
    "    2: \"Discharged/transferred to another short term hospital\",\n",
    "    3: \"Discharged/transferred to SNF\",\n",
    "    4: \"Discharged/transferred to ICF\",\n",
    "    5: \"Discharged/transferred to another type of inpatient care institution\",\n",
    "    6: \"Discharged/transferred to home with home health service\",\n",
    "    7: \"Left AMA\",\n",
    "    8: \"Discharged/transferred to home under care of Home IV provider\",\n",
    "    9: \"Admitted as an inpatient to this hospital\",\n",
    "    10: \"Neonate discharged to another hospital for neonatal aftercare\",\n",
    "    11: \"Expired\",\n",
    "    12: \"Still patient or expected to return for outpatient services\",\n",
    "    13: \"Hospice / home\",\n",
    "    14: \"Hospice / medical facility\",\n",
    "    15: \"Discharged/transferred within this institution to Medicare approved swing bed\",\n",
    "    16: \"Discharged/transferred/referred another institution for outpatient services\",\n",
    "    17: \"Discharged/transferred/referred to this institution for outpatient services\",\n",
    "    18: \"NULL\",\n",
    "    19: \"Expired at home. Medicaid only, hospice.\",\n",
    "    20: \"Expired in a medical facility. Medicaid only, hospice.\",\n",
    "    21: \"Expired, place unknown. Medicaid only, hospice.\",\n",
    "    22: \"Discharged/transferred to another rehab fac including rehab units of a hospital\",\n",
    "    23: \"Discharged/transferred to a long term care hospital\",\n",
    "    24: \"Discharged/transferred to a nursing facility certified under Medicaid but not certified under Medicare.\",\n",
    "    25: \"Not Mapped\",\n",
    "    26: \"Unknown/Invalid\",\n",
    "    30: \"Discharged/transferred to another Type of Health Care Institution not Defined Elsewhere\",\n",
    "    27: \"Discharged/transferred to a federal health care facility.\",\n",
    "    28: \"Discharged/transferred/referred to a psychiatric hospital or psychiatric distinct part unit of a hospital\",\n",
    "    29: \"Discharged/transferred to a Critical Access Hospital (CAH).\"\n",
    "}\n",
    "\n",
    "admission_source_id = {\n",
    "    1: \"Physician Referral\",\n",
    "    2: \"Clinic Referral\",\n",
    "    3: \"HMO Referral\",\n",
    "    4: \"Transfer from a hospital\",\n",
    "    5: \"Transfer from a Skilled Nursing Facility (SNF)\",\n",
    "    6: \"Transfer from another health care facility\",\n",
    "    7: \"Emergency Room\",\n",
    "    8: \"Court/Law Enforcement\",\n",
    "    9: \"Not Available\",\n",
    "    10: \"Transfer from critical access hospital\",\n",
    "    11: \"Normal Delivery\",\n",
    "    12: \"Premature Delivery\",\n",
    "    13: \"Sick Baby\",\n",
    "    14: \"Extramural Birth\",\n",
    "    15: \"Not Available\",\n",
    "    17: \"NULL\",\n",
    "    18: \"Transfer From Another Home Health Agency\",\n",
    "    19: \"Readmission to Same Home Health Agency\",\n",
    "    20: \"Not Mapped\",\n",
    "    21: \"Unknown/Invalid\",\n",
    "    22: \"Transfer from hospital inpt/same fac reslt in a sep claim\",\n",
    "    23: \"Born inside this hospital\",\n",
    "    24: \"Born outside this hospital\",\n",
    "    25: \"Transfer from Ambulatory Surgery Center\",\n",
    "    26: \"Transfer from Hospice\"\n",
    "}\n",
    "\n",
    "dosage={0:\"No\",1:\"Down\",2:\"Up\",3:\"Steady\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports\n",
    "Copied from previous project to have a foundation. We can delete unused ones later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from scipy.stats import gaussian_kde\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import StandardScaler, OrdinalEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.cluster import MiniBatchKMeans\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import dataset and print basic info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"diabetic_data.csv\")\n",
    "\n",
    "print(data.info())\n",
    "print(data.head())\n",
    "\n",
    "# Replace \"?\" and \"None\" with \"NaN\" and check for missing values\n",
    "data.replace('?', np.nan, inplace=True)\n",
    "data.replace('None', np.nan, inplace=True)\n",
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Handle missing values\n",
    "Drop columns with too many missing values and fill in others."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mostly missing values and/or low relevance\n",
    "# E.g. max_glu_serum and A1Cresult are relevant, but have 94% and 83% missing values.\n",
    "data.drop(columns=['weight', \n",
    "                   'payer_code', \n",
    "                   'max_glu_serum', \n",
    "                   'A1Cresult',\n",
    "                   'encounter_id',\n",
    "                   'patient_nbr'], inplace=True)\n",
    "\n",
    "# Many missing values, but potentially high relevance\n",
    "data['medical_specialty'].fillna('Unknown', inplace=True)\n",
    "\n",
    "# Few missing values\n",
    "data['race'].fillna('Unknown', inplace=True)\n",
    "data['diag_1'].fillna('Unknown', inplace=True)\n",
    "data['diag_2'].fillna('Unknown', inplace=True)\n",
    "data['diag_3'].fillna('Unknown', inplace=True)\n",
    "\n",
    "# Remove 3 rows where gender is \"Unknown/Invalid\"\n",
    "data = data[data['gender'] != 'Unknown/Invalid']\n",
    "\n",
    "# Display updated summary of missing values\n",
    "print(data.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Binary Encoding\n",
    "data['gender'] = data['gender'].map({'Male': 1, 'Female': 0})\n",
    "data['change'] = data['change'].map({'Ch': 1, 'No': 0})\n",
    "data['diabetesMed'] = data['diabetesMed'].map({'Yes': 1, 'No': 0})\n",
    "\n",
    "# Numeric mapping for medication columns\n",
    "medication_columns = ['metformin', 'repaglinide', 'nateglinide', 'chlorpropamide', \n",
    "                      'glimepiride', 'acetohexamide', 'glipizide', 'glyburide', \n",
    "                      'tolbutamide', 'pioglitazone', 'rosiglitazone', 'acarbose', \n",
    "                      'miglitol', 'troglitazone', 'tolazamide', 'examide', \n",
    "                      'citoglipton', 'insulin', 'glyburide-metformin', \n",
    "                      'glipizide-metformin', 'glimepiride-pioglitazone', \n",
    "                      'metformin-rosiglitazone', 'metformin-pioglitazone']\n",
    "\n",
    "data[medication_columns] = data[medication_columns].replace({'Steady': 1, 'No': 0, 'Down': -1, 'Up': 2})\n",
    "\n",
    "# One-Hot Encoding for categorical columns\n",
    "data = pd.get_dummies(data, columns=['race', 'medical_specialty', 'admission_type_id', 'discharge_disposition_id', 'diag_1', 'diag_2', 'diag_3'], drop_first=True)\n",
    "\n",
    "\n",
    "# Ordinal Encoding for ordered categories\n",
    "age_order = [['[0-10)', '[10-20)', '[20-30)', '[30-40)', '[40-50)', '[50-60)', '[60-70)', '[70-80)', '[80-90)', '[90-100)']]\n",
    "readmitted_order = [['NO', '>30', '<30']]\n",
    "ordinal_encoder = OrdinalEncoder(categories=age_order + readmitted_order)\n",
    "data[['age', 'readmitted']] = ordinal_encoder.fit_transform(data[['age', 'readmitted']])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split into features and target\n",
    "X = data.drop('readmitted', axis=1)\n",
    "y = data['readmitted']\n",
    "\n",
    "# Split into training and testing\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "numerical_features = ['time_in_hospital', 'num_lab_procedures', 'num_procedures', 'num_medications', 'number_outpatient', 'number_emergency', 'number_inpatient']\n",
    "X_train[numerical_features] = scaler.fit_transform(X_train[numerical_features])\n",
    "X_test[numerical_features] = scaler.transform(X_test[numerical_features])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing for missing values, troubleshooting\n",
    "print(\"Missing values in X_train:\", X_train.isnull().sum().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model choice\n",
    "We decided to start with two classification and one clustering algorithm.\n",
    "### Logistic Regression\n",
    "- Effective for rougly linear relationships\n",
    "- Interpretable (giving us an idea of the meaning of each feature)\n",
    "- Efficient for large datasets\n",
    "### Random Forest\n",
    "- Captures complex, non-linear relationships (good counterpart to Logisitc Regression)\n",
    "- Allows determining feature importance\n",
    "- Usually performs well without hypertuning\n",
    "### K-Means Clustering\n",
    "- Easy to interpret\n",
    "- Effective for grouping patients with similar characteristics\n",
    "- Might still be fast enough for a dataset of our size\n",
    "- There are different ways to make K-Means faster, if needed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize\n",
    "log_reg = LogisticRegression(solver='saga', max_iter=1000, random_state=42)\n",
    "\n",
    "# train\n",
    "log_reg.fit(X_train, y_train)\n",
    "\n",
    "# Predict\n",
    "y_pred_log_reg = log_reg.predict(X_test)\n",
    "\n",
    "# Evaluate\n",
    "print(\"Logistic Regression Accuracy:\", accuracy_score(y_test, y_pred_log_reg))\n",
    "print(classification_report(y_test, y_pred_log_reg))\n",
    "print(confusion_matrix(y_test, y_pred_log_reg))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Seminar2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
